{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a923f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from datetime import datetime, timedelta\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "from scipy.special import comb\n",
    "import random\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from shapely import wkb\n",
    "import binascii\n",
    "from pyproj import Transformer\n",
    "from collections import defaultdict\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 6]\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"xtick.labelsize\"] = 15 \n",
    "plt.rcParams[\"ytick.labelsize\"] = 15 \n",
    "plt.rcParams[\"axes.labelsize\"] = 25\n",
    "plt.rcParams[\"legend.fontsize\"] = 20  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database credentials\n",
    "db_usr, db_pwd = '', '' # your database user name and password\n",
    "\n",
    "# database login\n",
    "host, port, db = 'nc-health-data-prod.cluster-ccsgl7rk4urn.eu-central-1.rds.amazonaws.com', 5432, 'master'\n",
    "engine = create_engine('postgresql://'+db_usr+':'+db_pwd+'@'+host+':'+str(port)+'/'+db)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_list(lst):\n",
    "    mapping = {}\n",
    "    \n",
    "    for item in lst:\n",
    "        # Use a tuple of the sorted first two elements as a key for the dictionary\n",
    "        key = tuple(sorted(item[:2]))\n",
    "        if key in mapping:\n",
    "            mapping[key].append(item[2])\n",
    "        else:\n",
    "            mapping[key] = [item[2]]\n",
    "    # Convert the dictionary back to the desired list format\n",
    "    result = [(k[0], k[1], mapping[k]) for k in mapping.keys()]\n",
    "\n",
    "    return result\n",
    "def sort_time(weight_list):\n",
    "    data = weight_list\n",
    "    # Extract the timestamps and create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Latitude\", \"Longitude\", \"Timestamp\"])\n",
    "\n",
    "    # Sort by Timestamp\n",
    "    df = df.sort_values(by=\"Timestamp\")\n",
    "\n",
    "    # Group and select the first timestamp of each group\n",
    "    df['group'] = (df['Timestamp'].diff() > pd.Timedelta(minutes=60)).cumsum()\n",
    "    df = df.groupby('group').first().reset_index(drop=True)\n",
    "    tuples = [tuple(row) for row in df.itertuples(index=False)]\n",
    "\n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8332847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating the DataFrame with the updated match information, German city names, and times\n",
    "# Creating the DataFrame with the updated match information, German city names, and times\n",
    "data_group_a = {\n",
    "    'City': ['München', 'Köln', 'Stuttgart', 'Köln', 'Frankfurt am Main', 'Stuttgart'],\n",
    "    'Date': ['2024-06-14', '2024-06-15', '2024-06-19', '2024-06-19', '2024-06-23', '2024-06-23'],\n",
    "    'Time': ['21:00', '15:00', '18:00', '21:00', '21:00', '21:00'],\n",
    "    'Population': [1471508, 1085664, 634830, 1085664, 753056, 634830],\n",
    "    'Match': [\n",
    "        'Germany 5 - 1 Scotland', \n",
    "        'Hungary 1 - 3 Switzerland', \n",
    "        'Germany 2 - 0 Hungary', \n",
    "        'Scotland 1 - 1 Switzerland', \n",
    "        'Switzerland 1 - 1 Germany', \n",
    "        'Scotland 0 - 1 Hungary'\n",
    "    ]\n",
    "}\n",
    "df_group_a = pd.DataFrame(data_group_a)\n",
    "\n",
    "data_group_b = {\n",
    "    'City': ['Berlin', 'Dortmund', 'Hamburg', 'Gelsenkirchen', 'Leipzig', 'Düsseldorf'],\n",
    "    'Date': ['2024-06-15', '2024-06-15', '2024-06-19', '2024-06-20', '2024-06-24', '2024-06-24'],\n",
    "    'Time': ['18:00', '21:00', '15:00', '21:00', '21:00', '21:00'],\n",
    "    'Population': [3769000, 588462, 1841179, 260000, 597493, 619294],\n",
    "    'Match': [\n",
    "        'Spain 3 - 0 Croatia', \n",
    "        'Italy 2 - 1 Albania', \n",
    "        'Croatia 2 - 2 Albania', \n",
    "        'Spain 1 - 0 Italy', \n",
    "        'Croatia 1 - 1 Italy', \n",
    "        'Albania 0 - 1 Spain'\n",
    "    ]\n",
    "}\n",
    "df_group_b = pd.DataFrame(data_group_b)\n",
    "\n",
    "data_group_c = {\n",
    "    'City': ['Stuttgart', 'Gelsenkirchen', 'München', 'Frankfurt am Main', 'Köln', 'München'],\n",
    "    'Date': ['2024-06-16', '2024-06-16', '2024-06-20', '2024-06-20', '2024-06-25', '2024-06-25'],\n",
    "    'Time': ['18:00', '21:00', '15:00', '18:00', '21:00', '21:00'],\n",
    "    'Population': [634830, 260000, 1472000, 753056, 1085664, 1472000],\n",
    "    'Match': [\n",
    "        'Slovenia 1 - 1 Denmark', \n",
    "        'Serbia 0 - 1 England', \n",
    "        'Slovenia 1 - 1 Serbia', \n",
    "        'Denmark 1 - 1 England', \n",
    "        'England 0 - 0 Slovenia', \n",
    "        'Denmark 0 - 0 Serbia'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_group_c= pd.DataFrame(data_group_c)\n",
    "\n",
    "data_group_d = {\n",
    "    'City': ['Hamburg', 'Düsseldorf', 'Berlin', 'Leipzig', 'Berlin', 'Dortmund'],\n",
    "    'Date': ['2024-06-16', '2024-06-17', '2024-06-21', '2024-06-21', '2024-06-25', '2024-06-25'],\n",
    "    'Time': ['15:00', '21:00', '18:00', '21:00', '18:00', '18:00'],\n",
    "    'Population': [1841179, 619294, 3769000, 597493, 3769000, 588462],\n",
    "    'Match': [\n",
    "        'Poland 1 - 2 Netherlands', \n",
    "        'Austria 0 - 1 France', \n",
    "        'Poland 1 - 3 Austria', \n",
    "        'Netherlands 0 - 0 France', \n",
    "        'Netherlands 2 - 3 Austria', \n",
    "        'France 1 - 1 Poland'\n",
    "    ]\n",
    "}\n",
    "df_group_d = pd.DataFrame(data_group_d)\n",
    "\n",
    "\n",
    "data_group_e = {\n",
    "    'City': ['München', 'Frankfurt am Main', 'Düsseldorf', 'Köln', 'Frankfurt am Main', 'Stuttgart'],\n",
    "    'Date': ['2024-06-17', '2024-06-17', '2024-06-21', '2024-06-22', '2024-06-26', '2024-06-26'],\n",
    "    'Time': ['15:00', '18:00', '15:00', '21:00', '18:00', '18:00'],\n",
    "    'Population': [1488202, 753056, 617280, 1080394, 753056, 635911],\n",
    "    'Match': [\n",
    "        'Romania 3 - 0 Ukraine', \n",
    "        'Belgium 0 - 1 Slovakia', \n",
    "        'Slovakia 1 - 2 Ukraine', \n",
    "        'Belgium 2 - 0 Romania', \n",
    "        'Slovakia 1 - 1 Romania', \n",
    "        'Ukraine 0 - 0 Belgium'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_group_e = pd.DataFrame(data_group_e)\n",
    "\n",
    "\n",
    "# Creating the DataFrame with the match information, cities, dates, times, and populations\n",
    "data_group_f = {\n",
    "    'City': ['Dortmund', 'Leipzig', 'Hamburg', 'Dortmund', 'Gelsenkirchen', 'Hamburg'],\n",
    "    'Date': ['2024-06-18', '2024-06-18', '2024-06-22', '2024-06-22', '2024-06-26', '2024-06-26'],\n",
    "    'Time': ['18:00', '21:00', '15:00', '18:00', '21:00', '21:00'],\n",
    "    'Population': [588462, 597493, 1841179, 588462, 260000, 1841179],\n",
    "    'Match': [\n",
    "        'Turkey 3 - 1 Georgia', \n",
    "        'Portugal 2 - 1 Czechia', \n",
    "        'Georgia 1 - 1 Czechia', \n",
    "        'Turkey 0 - 3 Portugal', \n",
    "        'Georgia 2 - 0 Portugal', \n",
    "        'Czechia 1 - 2 Turkey'\n",
    "    ]\n",
    "}\n",
    "df_group_f = pd.DataFrame(data_group_f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_eurocup_16th = {\n",
    "    'City': ['Dortmund', 'Berlin', 'Gelsenkirchen', 'Köln', 'Düsseldorf', 'Frankfurt am Main', 'München', 'Leipzig'],\n",
    "    'Date': ['2024-06-29', '2024-06-29', '2024-06-30', '2024-06-30', '2024-07-01', '2024-07-01', '2024-07-02', '2024-07-02'],\n",
    "    'Time': ['21:00', '18:00', '18:00', '21:00', '18:00', '21:00', '18:00', '21:00'],\n",
    "    'Population': [588462, 3644826, 260000, 1085664, 617280, 736414, 1471508, 597493],\n",
    "    'Match': [\n",
    "        'Germany 2 - 0 Denmark',\n",
    "        'Switzerland 2 - 0 Italy',\n",
    "        'England 2 - 1 Slovakia ',\n",
    "        'Spain 4 - 1 Georgia',\n",
    "        'France 1 - 0 Belgium',\n",
    "        'Portugal 0 - 0 Slovenia',\n",
    "        'Romania 0 - 3 Netherlands',\n",
    "        'Austria 1 - 2 Turkey'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_eurocup_16th = pd.DataFrame(data_eurocup_16th)\n",
    "\n",
    "# Creating the dataframe for the semifinals\n",
    "data_semifinals = {\n",
    "    'City': ['München', 'Dortmund'],\n",
    "    'Date': ['2024-07-09', '2024-07-10'],\n",
    "    'Time': ['21:00', '21:00'],\n",
    "    'Population': [1471508, 588462],\n",
    "    'Match': [\n",
    "        'Spain 2 - 1 France',\n",
    "        'Netherlands 1 - 2 England'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_semifinals = pd.DataFrame(data_semifinals)\n",
    "\n",
    "# Creating the dataframe for the quarterfinals\n",
    "data_quarterfinals = {\n",
    "    'City': ['Stuttgart', 'Hamburg', 'Berlin', 'Düsseldorf'],\n",
    "    'Date': ['2024-07-05', '2024-07-05', '2024-07-06', '2024-07-06'],\n",
    "    'Time': ['18:00', '21:00', '18:00', '21:00'],\n",
    "    'Population': [634830, 1841179, 3644826, 617280],\n",
    "    'Match': [\n",
    "        'Spain 2 - 1 Germany',\n",
    "        'Portugal 0 - 0 France ',\n",
    "        'Netherlands 2 - 1 Turkey',\n",
    "        'England 1 - 1 Switzerland'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_quarterfinals = pd.DataFrame(data_quarterfinals)\n",
    "\n",
    "data_final = {\n",
    "    'City': ['Berlin'],\n",
    "    'Date': ['2024-07-14'],\n",
    "    'Time': ['21:00'],\n",
    "    'Population': [3644826],\n",
    "    'Match': [\n",
    "        'Spain 2 - 1 England'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_final = pd.DataFrame(data_final)\n",
    "\n",
    "\n",
    "\n",
    "# Creating the DataFrame with the match information, cities, dates, times, and populations\n",
    "\n",
    "\n",
    "df_group_a['Group'] = 'Group A'\n",
    "df_group_b['Group'] = 'Group B'\n",
    "df_group_c['Group'] = 'Group C'\n",
    "df_group_d['Group'] = 'Group D'\n",
    "df_group_e['Group'] = 'Group E'\n",
    "df_group_f['Group'] = 'Group F'\n",
    "\n",
    "# Combine the DataFrames\n",
    "combined_df = pd.concat([df_group_a, df_group_b, df_group_c, df_group_d, df_group_e, df_group_f, df_eurocup_16th, df_quarterfinals, df_semifinals, df_final ], ignore_index=True)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c819d00",
   "metadata": {},
   "source": [
    "## (Fig 5) Heatmaps per city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af178c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "slots = 24\n",
    "start_date = datetime.strptime('2024-05-06', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2024-07-30', '%Y-%m-%d')\n",
    "city='Berlin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Define FIFA country codes\n",
    "fifa_country_codes = {\n",
    "    'Germany': 'GER', 'Scotland': 'SCO', 'Hungary': 'HUN', 'Switzerland': 'SUI', 'Spain': 'ESP',\n",
    "    'Croatia': 'CRO', 'Italy': 'ITA', 'Albania': 'ALB', 'Slovenia': 'SVN', 'Denmark': 'DEN',\n",
    "    'Serbia': 'SRB', 'Poland': 'POL', 'Netherlands': 'NED', 'Austria': 'AUT', 'France': 'FRA',\n",
    "    'Romania': 'ROU', 'Ukraine': 'UKR', 'Belgium': 'BEL', 'Slovakia': 'SVK', 'Turkey': 'TUR',\n",
    "    'Georgia': 'GEO', 'Portugal': 'POR', 'Czechia': 'CZE'\n",
    "}\n",
    "\n",
    "# Function to replace country names with FIFA codes\n",
    "def map_fifa_codes(match_str):\n",
    "    # Extract teams using regex\n",
    "    match = re.match(r'^(.*) (\\d+) - (\\d+) (.*)$', match_str)\n",
    "    if match:\n",
    "        team1, score1, score2, team2 = match.groups()\n",
    "        # Map country names to FIFA codes\n",
    "        team1_code = fifa_country_codes.get(team1.strip(), team1.strip())\n",
    "        team2_code = fifa_country_codes.get(team2.strip(), team2.strip())\n",
    "        return f\"{team1_code} {score1} - {score2} {team2_code}\"\n",
    "    return match_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f366cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event details from combined_df\n",
    "event_details = combined_df[['City', 'Date', 'Time', 'Match']]\n",
    "\n",
    "# Convert Date column to datetime\n",
    "event_details['Date'] = pd.to_datetime(event_details['Date'])\n",
    "\n",
    "# Extract event times and dates\n",
    "event_times = {\n",
    "    (row['City'], datetime.strptime(row['Date'].strftime('%Y-%m-%d') + ' ' + row['Time'], '%Y-%m-%d %H:%M')): row['Match']\n",
    "    for index, row in event_details.iterrows()\n",
    "    if start_date <= row['Date'] <= end_date\n",
    "}\n",
    "delta = end_date - start_date\n",
    "days_list = [(start_date + timedelta(days=i)).strftime('%Y-%m-%d') for i in range(delta.days + 1)]\n",
    "print(days_list)\n",
    "date_range = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "number_of_days = len(date_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb18ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "df_total = pd.DataFrame()\n",
    "data_dict = {}\n",
    "for day in days_list:\n",
    "    query =f\"\"\"\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT cnv.*, t2p.*\n",
    "        FROM covid_network_sdkv6_tl5_10m cnv \n",
    "        JOIN tile2plz t2p ON cnv.tile_id = t2p.tile_id\n",
    "        WHERE \"day\" = '{day}'\n",
    "    ) t1\n",
    "    JOIN covid_plz_populate cpp ON t1.plz = cpp.id_plz5 \n",
    "    WHERE city = '{city}'\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    didlist=[]\n",
    "    pairlist=[]\n",
    "\n",
    "    df_day= pd.DataFrame(pd.read_sql_query(query, conn))\n",
    "    transformer = Transformer.from_crs(\"epsg:3857\", \"epsg:4326\")\n",
    "\n",
    "    # iterate over contact events\n",
    "    for dids, sources, in_stad, point, time in zip(df_day.dids, df_day.sources, df_day.dist_stads, df_day.geopoint, df_day.stime):\n",
    "        ngps = 1 if (in_stad==True) else 0\n",
    "        for i, si in zip(dids, sources[1:-1].split(',')):\n",
    "            for j, sj in zip(dids, sources[1:-1].split(',')):\n",
    "                if i < j and [si, sj].count('GPS') >= ngps:\n",
    "                    # collect dids in did list\n",
    "                    didlist.append(i)\n",
    "                    didlist.append(j)\n",
    "                    bytes_object = binascii.unhexlify(point)\n",
    "                    geometry = wkb.loads(bytes_object)\n",
    "                    # Transformer from EPSG:3857 to EPSG:4326\n",
    "\n",
    "                    # Assuming that `geometry` is a Point\n",
    "                    lon, lat = transformer.transform(geometry.x, geometry.y)\n",
    "                    # collect pairs of dids in pair list\n",
    "                    pairlist.append((i, j, (lon, lat, time)))\n",
    "\n",
    "    # get unique dids and did pairs\n",
    "    print(f\"Checkpoint 1 at: {datetime.now()}\")\n",
    "    didlist, pairlist = list(set(didlist)), list(set(pairlist))\n",
    "    print(len(didlist))\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(didlist)\n",
    "    print(f\"Checkpoint 2 at: {datetime.now()}\")\n",
    "\n",
    "    pairlist_multiple = consolidate_list(pairlist)\n",
    "    pairlist_multiple = [(node1, node2, sort_time(another_list)) for node1, node2, another_list in pairlist_multiple]\n",
    "    G.add_weighted_edges_from(pairlist_multiple)\n",
    "    print(len(G.edges()))\n",
    "    print(len(G.nodes()))\n",
    "    edges = list(G.edges(data=True))\n",
    "\n",
    "    for edge in edges:\n",
    "        node1, node2, attr = edge\n",
    "        for weight in attr['weight']:\n",
    "            matrix = np.zeros((1, slots), dtype=int)\n",
    "            gps_point = weight[:2]\n",
    "            timestamp = weight[2]\n",
    "            if timestamp.tzinfo is not None:\n",
    "                timestamp = timestamp.tz_localize(None)\n",
    "            hour = timestamp.hour\n",
    "            minute = timestamp.minute\n",
    "            interval_index = (hour * 60 + minute) // 60\n",
    "            matrix[0][interval_index] = 1\n",
    "            key = (node1, node2, day)\n",
    "            if key in data_dict:\n",
    "                data_dict[key]['vector'] += matrix.flatten()\n",
    "                data_dict[key]['gps_points'].append(gps_point)\n",
    "            else:\n",
    "                data_dict[key] = {\n",
    "                    'did1': node1,\n",
    "                    'did2': node2,\n",
    "                    'vector': matrix.flatten(),\n",
    "                    'gps_points': [gps_point],\n",
    "                    'day': day\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6068bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c815c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "number_of_days = len(date_range)\n",
    "organized_data = defaultdict(lambda: np.zeros((number_of_days, slots)))\n",
    "\n",
    "\n",
    "for (did1, did2, date_str), info in data_dict.items():\n",
    "    date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    index = (date - start_date).days\n",
    "    if 0 <= index < number_of_days:\n",
    "        organized_data[(did1, did2)][index, :] = info['vector']\n",
    "    else:\n",
    "        print(f\"Index {index} is out of bounds for ({did1}, {did2}) with date {date_str}\")\n",
    "\n",
    "df_rows = []\n",
    "\n",
    "for (did1, did2), vectors in organized_data.items():\n",
    "    # Create a full vector matrix initialized with zeros\n",
    "    full_vector_matrix = np.zeros((number_of_days, slots))\n",
    "\n",
    "    # Directly assign the vectors to the corresponding dates\n",
    "    full_vector_matrix[:vectors.shape[0], :vectors.shape[1]] = vectors\n",
    "    # Sum the slots per day\n",
    "    daily_sums = full_vector_matrix.sum(axis=1)\n",
    "\n",
    "\n",
    "    # Append to the DataFrame rows\n",
    "    df_rows.append({'pair': f'{did1}-{did2}', 'vector': full_vector_matrix, 'daily_sums': daily_sums})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_rows)\n",
    "df['flattened_vector'] = df['vector'].apply(lambda x: x.reshape(-1))\n",
    "\n",
    "number_of_days = len(df['flattened_vector'].iloc[0]) // slots\n",
    "heatmap_data = np.zeros((number_of_days, slots))\n",
    "for _, row in df.iterrows():\n",
    "    matrix = np.array(row['vector']).reshape(number_of_days, slots)\n",
    "    heatmap_data += matrix\n",
    "    \n",
    "heatmap_data_df = pd.DataFrame(heatmap_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355bc80",
   "metadata": {},
   "source": [
    "## To replot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "city='Berlin'\n",
    "date_range = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "number_of_days = len(date_range)\n",
    "combined_df['Match'] = combined_df['Match'].apply(map_fifa_codes)\n",
    "# Event details from combined_df\n",
    "event_details = combined_df[['City', 'Date', 'Time', 'Match']]\n",
    "\n",
    "# Convert Date column to datetime\n",
    "event_details['Date'] = pd.to_datetime(event_details['Date'])\n",
    "\n",
    "# Extract event times and dates\n",
    "event_times = {\n",
    "    (row['City'], datetime.strptime(row['Date'].strftime('%Y-%m-%d') + ' ' + row['Time'], '%Y-%m-%d %H:%M')): row['Match']\n",
    "    for index, row in event_details.iterrows()\n",
    "    if start_date <= row['Date'] <= end_date\n",
    "}\n",
    "\n",
    "heatmap_data_df=pd.read_csv(f'data/heatmaps_16m_10m/heatmap_data_{city}_tl7_10m.csv')\n",
    "\n",
    "heatmap_data_df = heatmap_data_df.iloc[5:]\n",
    "heatmap_data = np.flipud(heatmap_data_df.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec829ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Assuming heatmap_data, start_date, number_of_days, slots, city, and event_times are already defined\n",
    "\n",
    "vmax_auto = np.max(heatmap_data)\n",
    "print(vmax_auto)\n",
    "fig, ax = plt.subplots(figsize=(40, 15))\n",
    "\n",
    "# Create the heatmap without the color bar\n",
    "cax = sns.heatmap(heatmap_data, cmap='YlGnBu', vmin=0, vmax=180, ax=ax, linewidths=.5)\n",
    "cbar = cax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=50)\n",
    "\n",
    "# Generate all dates within the range\n",
    "dates = [start_date + timedelta(days=i) for i in range(number_of_days)]\n",
    "\n",
    "# Identify all Sundays\n",
    "sundays = [date for date in dates if date.weekday() == 6]\n",
    "\n",
    "# Select every other Sunday\n",
    "sundays_every_two_weeks = sundays[::2]\n",
    "\n",
    "# Positions of the selected Sundays in the dates list\n",
    "sunday_positions = [dates.index(sunday) for sunday in sundays_every_two_weeks]\n",
    "\n",
    "# Set x-ticks at the positions of the selected Sundays\n",
    "ax.set_xticks(sunday_positions)\n",
    "\n",
    "# Set x-tick labels as the formatted dates\n",
    "xtick_labels = [sunday.strftime('%m/%d') for sunday in sundays_every_two_weeks]\n",
    "ax.set_xticklabels(xtick_labels, ha='right', fontsize=60)\n",
    "\n",
    "# Set y-ticks every 4 hours\n",
    "ax.set_yticks([i + 3.5 for i in range(0, slots, 4)])  # Ticks at 0, 4, 8, 12, 16, 20\n",
    "\n",
    "# Set y-tick labels corresponding to every 4 hours\n",
    "ax.set_yticklabels(reversed(range(0, slots, 4)), fontsize=60, rotation=0)\n",
    "\n",
    "# Move the y-axis label slightly to the right\n",
    "ax.set_ylabel(\"hour of the day\", fontsize=75, labelpad=30)  # Adjust 'labelpad' as needed\n",
    "\n",
    "ax.set_title(f\"{city}\", fontsize=80)\n",
    "\n",
    "# Define a threshold for deciding if the text color should be orange\n",
    "threshold = 40  # Adjust this value based on your data\n",
    "\n",
    "# Plot events\n",
    "for (event_city, event_time), event_name in event_times.items():\n",
    "    if event_city == city:\n",
    "        event_day_index = (event_time.date() - start_date.date()).days\n",
    "        event_hour_index = slots - 1 - event_time.hour  # Adjusted for 24 slots\n",
    "\n",
    "        match_parts = event_name.split(\" \")\n",
    "        team1 = match_parts[0][:3].upper()\n",
    "        score1 = match_parts[1]\n",
    "        score2 = match_parts[3]\n",
    "        team2 = match_parts[4][:3].upper()\n",
    "\n",
    "        team_abbreviation = f\"{team1}-{team2}\"\n",
    "        \n",
    "        # Determine if the value in heatmap_data is below the threshold\n",
    "        cell_value = heatmap_data[event_hour_index, event_day_index]\n",
    "        if cell_value < threshold:\n",
    "            text_color = 'black'\n",
    "            font_weight = 'bold'\n",
    "        else:\n",
    "            text_color = 'black'\n",
    "            font_weight = 'bold'\n",
    "        \n",
    "        ax.text(event_day_index + 0.5, event_hour_index + 0.5, team_abbreviation,\n",
    "                ha='center', va='center', color=text_color, fontsize=30, rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "ax.set_xlabel(\"day\", fontsize=75, labelpad=30)\n",
    "\n",
    "# Corrected file path handling\n",
    "#output_file = rf\"C:nc-euro24\\plots\\heatmap_{city}_tl7_10m.svg\"\n",
    "\n",
    "#plt.savefig(output_file, format=\"svg\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c96c5d",
   "metadata": {},
   "source": [
    "## Contacts before and after of the match\n",
    "\n",
    "We study 8 hours before of the match, 2 hours during the match and 2 hours aftewards. We normalized the number of contacts per hour and give to each curve a color depending on the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_entries(heatmap_data, target_time):\n",
    "    \"\"\"\n",
    "    give us entries for four hours before and two hours after the target time.\n",
    "    \n",
    "    Parameters:\n",
    "    heatmap_data (numpy array): An array of size (24, 1) representing heatmap data for 24 hours.\n",
    "    target_time (int): The target hour in the range of 0 to 23.\n",
    "    \n",
    "    Returns:\n",
    "    int: The sum of the entries for two hours before and three hours after the target time.\n",
    "    \"\"\"\n",
    "    heatmap_data = heatmap_data.flatten()\n",
    "    print(heatmap_data)\n",
    "    # Calculate the indices for two hours before and three hours after the target time\n",
    "    start_index = (target_time - 8) % 24\n",
    "    end_index = (target_time + 4) % 24\n",
    "    \n",
    "    # Handle the case where the interval wraps around midnight\n",
    "    if start_index < end_index:\n",
    "        relevant_entries = heatmap_data[start_index:end_index+1]\n",
    "    else:\n",
    "        relevant_entries = np.concatenate((heatmap_data[start_index:], heatmap_data[:end_index+1]))\n",
    "    print('relevant_entries',relevant_entries)\n",
    "    return relevant_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import binascii\n",
    "from shapely import wkb\n",
    "from pyproj import Transformer\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "slots=24\n",
    "\n",
    "\n",
    "def matches_contacts(city, date):\n",
    "    days_list = [date]  # Assuming we're dealing with one date at a time for simplicity\n",
    "    \n",
    "    for day in days_list:\n",
    "        print(day)\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM (\n",
    "                SELECT cnv.*, t2p.*\n",
    "                FROM covid_network_sdkv6_tl7_10m cnv \n",
    "                JOIN tile2plz t2p ON cnv.tile_id = t2p.tile_id\n",
    "                WHERE \"day\" ='{day}' \n",
    "            ) t1\n",
    "            JOIN covid_plz_populate cpp ON t1.plz = cpp.id_plz5 \n",
    "            WHERE city= '{city}' \n",
    "        \"\"\"\n",
    "\n",
    "        didlist = []\n",
    "        pairlist = []\n",
    "\n",
    "        df_day = pd.DataFrame(pd.read_sql_query(query, conn))\n",
    "        print(df_day)\n",
    "        transformer = Transformer.from_crs(\"epsg:3857\", \"epsg:4326\")\n",
    "\n",
    "        for dids, sources, in_stad, point, stime in zip(df_day.dids, df_day.sources, df_day.dist_stads, df_day.geopoint, df_day.stime):\n",
    "            ngps = 1 if (in_stad == True) else 0\n",
    "            bytes_object = binascii.unhexlify(point)\n",
    "            geometry = wkb.loads(bytes_object)\n",
    "            lon, lat = transformer.transform(geometry.x, geometry.y)\n",
    "            for i, si in zip(dids, sources[1:-1].split(',')):\n",
    "                for j, sj in zip(dids, sources[1:-1].split(',')):\n",
    "                    if i < j and [si, sj].count('GPS') >= ngps:\n",
    "                        didlist.append(i)\n",
    "                        didlist.append(j)\n",
    "                        pairlist.append((i, j, (lon, lat, stime)))\n",
    "\n",
    "        print(f\"Checkpoint 1 at: {datetime.now()}\")\n",
    "        didlist, pairlist = list(set(didlist)), list(set(pairlist))\n",
    "        print(len(didlist))\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(didlist)\n",
    "        print(f\"Checkpoint 2 at: {datetime.now()}\")\n",
    "        pairlist_multiple = consolidate_list(pairlist)\n",
    "        pairlist_multiple = [(node1, node2, sort_time(another_list)) for node1, node2, another_list in pairlist_multiple]\n",
    "        G.add_weighted_edges_from(pairlist_multiple)\n",
    "        print(len(G.edges()))\n",
    "        edges = list(G.edges(data=True))\n",
    "\n",
    "        data_dict = {}\n",
    "        for edge in edges:\n",
    "            node1, node2, attr = edge\n",
    "            for weight in attr['weight']:\n",
    "                matrix = np.zeros((1, slots), dtype=int)  # 24 hours * 6 intervals per hour\n",
    "                gps_point = weight[:2]\n",
    "                timestamp = weight[2]\n",
    "                if timestamp.tzinfo is not None:\n",
    "                    timestamp = timestamp.tz_localize(None)\n",
    "                hour = timestamp.hour\n",
    "                minute = timestamp.minute\n",
    "                interval_index = (hour * 60 + minute) // (1* 60)\n",
    "\n",
    "                matrix[0][interval_index] = 1\n",
    "                key = (node1, node2, day)\n",
    "                if key in data_dict:\n",
    "                    data_dict[key]['vector'] += matrix.flatten()\n",
    "                    data_dict[key]['gps_points'].append(gps_point)\n",
    "                else:\n",
    "                    data_dict[key] = {\n",
    "                        'did1': node1,\n",
    "                        'did2': node2,\n",
    "                        'vector': matrix.flatten(),\n",
    "                        'gps_points': [gps_point],\n",
    "                        'day': day\n",
    "                    }\n",
    "                    \n",
    "        number_of_days = 1\n",
    "        # Initialize the organized data structure\n",
    "        organized_data = defaultdict(lambda: np.zeros((number_of_days, slots)))  # Default to zero matrix\n",
    "\n",
    "        # Populate the data structure\n",
    "        for (did1, did2, date_str), info in data_dict.items():\n",
    "            date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "            index = 0\n",
    "\n",
    "            # Ensure the index is within the valid range\n",
    "            if 0 <= index < number_of_days:\n",
    "                organized_data[(did1, did2)][index, :] = info['vector']\n",
    "            else:\n",
    "                print(f\"Index {index} is out of bounds for ({did1}, {did2}) with date {date_str}\")\n",
    "\n",
    "        # List to hold the DataFrame rows\n",
    "        df_rows = []\n",
    "\n",
    "        # Iterate through the organized data\n",
    "        for (did1, did2), vectors in organized_data.items():\n",
    "            # Create a full vector matrix initialized with zeros\n",
    "            full_vector_matrix = np.zeros((number_of_days, slots))\n",
    "\n",
    "            # Directly assign the vectors to the corresponding dates\n",
    "            full_vector_matrix[:vectors.shape[0], :vectors.shape[1]] = vectors\n",
    "\n",
    "            # Append to the DataFrame rows\n",
    "            df_rows.append({'did1': did1, 'did2': did2, 'vector': full_vector_matrix})\n",
    "\n",
    "        # Create the DataFrame\n",
    "        df = pd.DataFrame(df_rows)\n",
    "\n",
    "        # Flatten the vector column efficiently using np.reshape\n",
    "        df['flattened_vector'] = df['vector'].apply(lambda x: x.reshape(-1))\n",
    "\n",
    "        print('vector', len(df['flattened_vector'][0]))\n",
    "        \n",
    "        number_of_days = len(df['flattened_vector'].iloc[0]) // slots# Assuming all vectors are the same length and correctly formatted\n",
    "        print(number_of_days)\n",
    "        heatmap_data = np.zeros((1, slots))\n",
    "        for _, row in df.iterrows():\n",
    "            matrix = np.array(row['vector']).reshape(number_of_days, slots)\n",
    "            heatmap_data += matrix\n",
    "\n",
    "        # Flip the heatmap data vertically to display 0 to 23 from bottom to top\n",
    "        heatmap_data = np.flipud(heatmap_data)\n",
    "        print(heatmap_data)\n",
    "        \n",
    "\n",
    "                    \n",
    "\n",
    "        return heatmap_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0646af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "matches = []\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in combined_df.iterrows():\n",
    "    city = row['City']\n",
    "    date = row['Date']\n",
    "    \n",
    "    # Get the heatmap data for the current city and date\n",
    "    heatmap_data = matches_contacts(city, date)\n",
    "    \n",
    "    # Extract the necessary information from the row\n",
    "    time = row['Time']\n",
    "    match = row['Match']\n",
    "    \n",
    "    # Extract the target hour from the time string\n",
    "    target_hour = int(time.split(':')[0])\n",
    "    print(f\"Processing {city} on {date} at {time} for match {match}\")\n",
    "    print('Current heatmap:', heatmap_data)\n",
    "    print('Target hour:', target_hour)\n",
    "    \n",
    "    # Get relevant entries from the heatmap data\n",
    "    result = relevant_entries(heatmap_data, target_hour)\n",
    "    print('Result:', result)\n",
    "    \n",
    "    # Append the results and matches to their respective lists\n",
    "    results.append(result)\n",
    "    matches.append(match)\n",
    "\n",
    "# Add the results and matches to the DataFrame\n",
    "combined_df['Result'] = results\n",
    "combined_df['MatchLabel'] = matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df['Result'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to normalize a list of numbers\n",
    "def normalize_list(lst):\n",
    "    total = sum(lst)\n",
    "    return [x / total for x in lst] if total != 0 else lst\n",
    "\n",
    "# Apply normalization to the 'Result' column\n",
    "combined_df['NormalizedResult'] = combined_df['Result'].apply(lambda x: normalize_list(x))\n",
    "\n",
    "# Now combined_df has a new column 'NormalizedResult' with the normalized values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095bf319",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df['NormalizedResult'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929abaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract unique cities for color differentiation\n",
    "cities = combined_df['City'].unique()\n",
    "colors = plt.cm.get_cmap('tab10', len(cities))\n",
    "\n",
    "# Create a dictionary to store colors for each city\n",
    "city_colors = {city: colors(i) for i, city in enumerate(cities)}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each row in NormalizedResult with a different color per city\n",
    "for _, row in combined_df.iterrows():\n",
    "    city = row['City']\n",
    "    plt.plot(range(1, 14), row['NormalizedResult'], color=city_colors[city], label=city)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Entry Number')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.title('Normalized Result by City')\n",
    "\n",
    "# Create a custom legend with unique cities\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(), title=\"City\", loc='upper right')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a47f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the color map based on the time of the match\n",
    "times = combined_df['Time'].apply(lambda x: int(x.split(':')[0]) + int(x.split(':')[1])/60)  # Convert time to decimal hours\n",
    "norm = plt.Normalize(vmin=times.min(), vmax=times.max())\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each row in NormalizedResult with color based on time of the match\n",
    "for _, row in combined_df.iterrows():\n",
    "    time = int(row['Time'].split(':')[0]) + int(row['Time'].split(':')[1])/60\n",
    "    plt.plot(range(1, 14), row['NormalizedResult'], color=cmap(norm(time)))\n",
    "\n",
    "# Add color bar to represent time\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm)\n",
    "cbar.set_label('Time of Match (hours)')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Entry Number')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.title('Normalized Result Colored by Time of Match')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63372a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter the DataFrame to include only rows where Time is '18:00'\n",
    "filtered_df = combined_df[combined_df['Time'] == '18:00']\n",
    "\n",
    "# Extract unique cities for color differentiation\n",
    "cities = filtered_df['City'].unique()\n",
    "colors = plt.cm.get_cmap('tab10', len(cities))\n",
    "\n",
    "# Create a dictionary to store colors for each city\n",
    "city_colors = {city: colors(i) for i, city in enumerate(cities)}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each row in NormalizedResult with a different color per city\n",
    "for _, row in filtered_df.iterrows():\n",
    "    city = row['City']\n",
    "    plt.plot(range(1, 14), row['NormalizedResult'], color=city_colors[city], label=city)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Entry Number')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.title('Normalized Result by City for Time 18:00')\n",
    "\n",
    "# Create a custom legend with unique cities\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(), title=\"City\", loc='upper right')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assume the 'Population' column exists in the combined_df with the population size for each city\n",
    "\n",
    "# Classify cities based on population size\n",
    "small_cities = combined_df[combined_df['Population'] < 600000]['City'].unique()\n",
    "medium_cities = combined_df[(combined_df['Population'] >= 600_000) & (combined_df['Population'] < 1_000_000)]['City'].unique()\n",
    "large_cities = combined_df[combined_df['Population'] >= 1_000_000]['City'].unique()\n",
    "\n",
    "# Sum the 'NormalizedResult' vectors for small, medium, and large cities\n",
    "small_group_sum = combined_df[combined_df['City'].isin(small_cities)].groupby('City')['NormalizedResult'].apply(lambda x: np.sum(np.array(x.tolist()), axis=0)).sum()\n",
    "medium_group_sum = combined_df[combined_df['City'].isin(medium_cities)].groupby('City')['NormalizedResult'].apply(lambda x: np.sum(np.array(x.tolist()), axis=0)).sum()\n",
    "large_group_sum = combined_df[combined_df['City'].isin(large_cities)].groupby('City')['NormalizedResult'].apply(lambda x: np.sum(np.array(x.tolist()), axis=0)).sum()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Add grey shaded area from 4 to 6 on the x-axis\n",
    "plt.axvspan(8, 10, color='grey', alpha=0.3)\n",
    "\n",
    "# Plot the summed vectors for small, medium, and large population groups\n",
    "plt.plot(range(1, 14), small_group_sum, label='Small Population (< 1 million)', color='blue')\n",
    "plt.plot(range(1, 14), medium_group_sum, label='Medium Population (600k - 1 million)', color='green')\n",
    "plt.plot(range(1, 14), large_group_sum, label='Large Population (> 1 million)', color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('hours')\n",
    "plt.ylabel('Summed Normalized Value')\n",
    "plt.title('Summed Normalized Results by Population Size')\n",
    "plt.legend(title=\"Population Group\", loc='upper right')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a DataFrame called `combined_df` with a 'NormalizedResult' column\n",
    "# which contains lists of 9 values (one per entry)\n",
    "\n",
    "# Extract all entries into separate lists\n",
    "entries = np.array(combined_df['NormalizedResult'].tolist()).T\n",
    "\n",
    "# Calculate means and standard deviations for each entry\n",
    "means = np.mean(entries, axis=1)\n",
    "std_devs = np.std(entries, axis=1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.axvspan(8, 10, color='grey', alpha=0.3)\n",
    "\n",
    "# Create boxplots for each entry\n",
    "sns.boxplot(data=entries.T, palette=\"pastel\")\n",
    "\n",
    "# Plot the means and connect them with a line\n",
    "plt.plot(range(13), means, marker='o', color='black', label='Mean Value')\n",
    "\n",
    "# Add error bars for standard deviations\n",
    "plt.errorbar(range(13), means, yerr=std_devs, fmt='o', color='black', capsize=5)\n",
    "plt.xticks(ticks=range(0, 13), labels=range(-8, 5))\n",
    "# Add labels and title\n",
    "plt.xlabel('Entry Number')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Distribution of Each Entry with Mean and Standard Deviation')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique city names with population under 1.5 million\n",
    "small_cities = combined_df[combined_df['Population'] < 600000]['City'].unique()\n",
    "\n",
    "# Filter the DataFrame for those small cities\n",
    "small_cities_df = combined_df[combined_df['City'].isin(small_cities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b288e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Extract all entries into separate lists for small cities\n",
    "entries = np.array(small_cities_df['NormalizedResult'].tolist()).T\n",
    "\n",
    "# Calculate means and standard deviations for each entry\n",
    "means = np.mean(entries, axis=1)\n",
    "std_devs = np.std(entries, axis=1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Add grey shaded area from 3 to 5 on the x-axis\n",
    "plt.axvspan(7, 9, color='grey', alpha=0.3)\n",
    "\n",
    "# Create boxplots for each entry\n",
    "sns.boxplot(data=entries.T, palette=\"pastel\")\n",
    "\n",
    "# Plot the means and connect them with a line\n",
    "plt.plot(range(13), means, marker='o', color='black', label='Mean Value')\n",
    "\n",
    "# Add error bars for standard deviations\n",
    "plt.errorbar(range(13), means, yerr=std_devs, fmt='o', color='black', capsize=5)\n",
    "# Set x-ticks from -3 to 5\n",
    "plt.xticks(ticks=range(13), labels=range(-7, 6))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('hours')\n",
    "plt.ylabel(' normalized number of contacts')\n",
    "plt.title('distribution of the normalized number of contact per hour with for small cities (under 600k)')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfd8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique city names with population between 600,000 and 1 million\n",
    "medium_cities = combined_df[(combined_df['Population'] > 600_000) & (combined_df['Population'] < 1_000_000)]['City'].unique()\n",
    "\n",
    "# Filter the DataFrame for those medium cities\n",
    "medium_cities_df = combined_df[combined_df['City'].isin(medium_cities)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd83f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already defined `large_cities_df` by filtering `combined_df`\n",
    "\n",
    "# Extract all entries into separate lists for large cities\n",
    "entries = np.array(medium_cities_df['NormalizedResult'].tolist()).T\n",
    "\n",
    "# Calculate means and standard deviations for each entry\n",
    "means = np.mean(entries, axis=1)\n",
    "std_devs = np.std(entries, axis=1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Add grey shaded area from 3 to 5 on the x-axis\n",
    "plt.axvspan(7, 9, color='grey', alpha=0.3)\n",
    "\n",
    "# Create boxplots for each entry\n",
    "sns.boxplot(data=entries.T, palette=\"pastel\")\n",
    "\n",
    "# Plot the means and connect them with a line\n",
    "plt.plot(range(13), means, marker='o', color='black', label='Mean Value')\n",
    "\n",
    "# Add error bars for standard deviations\n",
    "plt.errorbar(range(13), means, yerr=std_devs, fmt='o', color='black', capsize=5)\n",
    "\n",
    "# Set x-ticks from -3 to 5\n",
    "plt.xticks(ticks=range(13), labels=range(-7, 6))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Entry Number (-3 to 5)')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Distribution of Each Entry with Mean and Standard Deviation for Large Cities')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56fdd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique city names with population under 1.5 million\n",
    "large_cities = combined_df[combined_df['Population'] > 1000000]['City'].unique()\n",
    "\n",
    "# Filter the DataFrame for those small cities\n",
    "large_cities_df = combined_df[combined_df['City'].isin(large_cities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344adc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already defined `large_cities_df` by filtering `combined_df`\n",
    "\n",
    "# Extract all entries into separate lists for large cities\n",
    "entries = np.array(large_cities_df['NormalizedResult'].tolist()).T\n",
    "\n",
    "# Calculate means and standard deviations for each entry\n",
    "means = np.mean(entries, axis=1)\n",
    "std_devs = np.std(entries, axis=1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Add grey shaded area from 3 to 5 on the x-axis\n",
    "plt.axvspan(7, 9, color='grey', alpha=0.3)\n",
    "\n",
    "# Create boxplots for each entry\n",
    "sns.boxplot(data=entries.T, palette=\"pastel\")\n",
    "\n",
    "# Plot the means and connect them with a line\n",
    "plt.plot(range(13), means, marker='o', color='black', label='Mean Value')\n",
    "\n",
    "# Add error bars for standard deviations\n",
    "plt.errorbar(range(13), means, yerr=std_devs, fmt='o', color='black', capsize=5)\n",
    "\n",
    "# Set x-ticks from -3 to 5\n",
    "plt.xticks(ticks=range(13), labels=range(-7, 6))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Entry Number (-3 to 5)')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Distribution of Each Entry with Mean and Standard Deviation for Large Cities')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d5fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assume the combined_df DataFrame is already loaded and contains 'City', 'Population', and 'NormalizedResult'\n",
    "\n",
    "# Expand the 'NormalizedResult' column into separate columns for each entry\n",
    "expanded_df = pd.DataFrame(combined_df['NormalizedResult'].tolist(), index=combined_df.index)\n",
    "expanded_df.columns = [f'Entry {i+1}' for i in range(expanded_df.shape[1])]\n",
    "\n",
    "# Add back the 'City' and 'Population' columns\n",
    "expanded_df['City'] = combined_df['City']\n",
    "expanded_df['Population'] = combined_df['Population']\n",
    "\n",
    "# Melt the DataFrame to get a long-form DataFrame suitable for seaborn\n",
    "melted_df = pd.melt(expanded_df, id_vars=['City', 'Population'], var_name='Entry', value_name='Normalized Value')\n",
    "\n",
    "# Map each city's population to point size\n",
    "melted_df['Size'] = melted_df['Population'] / 100000  # Adjust scaling factor as needed\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot using Seaborn scatterplot\n",
    "sns.scatterplot(data=melted_df, x='Entry', y='Normalized Value', \n",
    "                hue='City', size='Size', sizes=(20, 200), alpha=0.7, palette='tab10')\n",
    "\n",
    "\n",
    "# Set x-ticks from -3 to 5\n",
    "plt.xticks(ticks=range(13), labels=range(-7, 6))\n",
    "plt.axvspan(7, 9, color='grey', alpha=0.3)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Entry')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.title('Scatter Plot of Normalized Results by City with Population Size')\n",
    "plt.legend(title=\"City\", loc='upper right', bbox_to_anchor=(1.25, 1))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd40ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assume the combined_df DataFrame is already loaded and contains 'City', 'Population', 'Time', and 'NormalizedResult'\n",
    "\n",
    "# Expand the 'NormalizedResult' column into separate columns for each entry\n",
    "expanded_df = pd.DataFrame(combined_df['NormalizedResult'].tolist(), index=combined_df.index)\n",
    "expanded_df.columns = [f'Entry {i+1}' for i in range(expanded_df.shape[1])]\n",
    "\n",
    "# Add back the 'City', 'Population', and 'Time' columns\n",
    "expanded_df['City'] = combined_df['City']\n",
    "expanded_df['Population'] = combined_df['Population']\n",
    "expanded_df['Time'] = combined_df['Time']\n",
    "\n",
    "# Melt the DataFrame to get a long-form DataFrame suitable for seaborn\n",
    "melted_df = pd.melt(expanded_df, id_vars=['City', 'Population', 'Time'], \n",
    "                    var_name='Entry', value_name='Normalized Value')\n",
    "\n",
    "# Map each city's population to point size\n",
    "melted_df['Size'] = melted_df['Population'] / 100000  # Adjust scaling factor as needed\n",
    "\n",
    "# Filter to include only the times of interest\n",
    "filtered_df = melted_df[melted_df['Time'].isin(['15:00', '18:00', '21:00'])]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot using Seaborn scatterplot\n",
    "sns.scatterplot(data=filtered_df, x='Entry', y='Normalized Value', \n",
    "                hue='City', size='Size', sizes=(20, 200), alpha=0.7, palette='tab10')\n",
    "\n",
    "# Calculate and plot the mean normalized values for each entry by time\n",
    "mean_values = filtered_df.groupby(['Entry', 'Time'])['Normalized Value'].mean().unstack()\n",
    "\n",
    "# Plot lines connecting mean points for each time\n",
    "plt.plot(range(13), mean_values['15:00'], marker='o', color='blue', linestyle='-', label='15:00 Mean')\n",
    "plt.plot(range(13), mean_values['18:00'], marker='o', color='green', linestyle='-', label='18:00 Mean')\n",
    "plt.plot(range(13), mean_values['21:00'], marker='o', color='red', linestyle='-', label='21:00 Mean')\n",
    "\n",
    "\n",
    "# Set x-ticks from -3 to 5\n",
    "plt.xticks(ticks=range(13), labels=range(-7, 6))\n",
    "plt.axvspan(7, 9, color='grey', alpha=0.3)\n",
    "plt.xlabel('hours')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.title('Scatter Plot of Normalized Results by City with Time-Specific Means')\n",
    "plt.legend(title=\"City and Time\", loc='upper right', bbox_to_anchor=(1.25, 1))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b6ba31",
   "metadata": {},
   "source": [
    "## Fig_6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "combined_df=pd.read_csv('data/fig_6/number_of_contacts_per_day_per_match_tl7_10m_fig_6.csv')\n",
    "combined_df[\"NormalizedResult\"] = combined_df[\"NormalizedResult\"].apply(ast.literal_eval)\n",
    "combined_df\n",
    "combined_df['MatchType'] = np.where(\n",
    "    combined_df['Match'].str.contains(\"Germany\"), \n",
    "    \"Germany\", \n",
    "    \"Other\"\n",
    ")\n",
    "combined_df['HourOffsets'] = [list(range(-7, 6))] * len(combined_df)\n",
    "\n",
    "# Explode both the NormalizedResult and HourOffsets columns \n",
    "# so that each (hour offset, normalized value) pair becomes its own row\n",
    "df_long = combined_df.explode(['NormalizedResult', 'HourOffsets']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_long,\n",
    "    x='HourOffsets',\n",
    "    y='NormalizedResult',\n",
    "    hue='MatchType',\n",
    "    palette={'Germany': 'blue', 'Other': 'orange'}\n",
    ")\n",
    "\n",
    "# Optionally shade the match window, e.g. from hour 0 to hour 2\n",
    "plt.axvspan(6.6, 9.4, color='grey', alpha=0.3)\n",
    "\n",
    "# Clean up axes and legend\n",
    "plt.xticks(ticks=range(0, 13), labels=range(-7, 6))\n",
    "plt.xlabel('time around the match in hours')\n",
    "plt.ylabel('normalized number of contacts')\n",
    "plt.legend(title='match type')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/fig_6/fig_6_tl7_10m.png', format=\"png\", dpi=300)  # 'png' should be a string\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `combined_df` is the main dataframe\n",
    "# Filter for rows where the match involves Germany\n",
    "germany_matches_df = combined_df[combined_df['Match'].str.contains(\"Germany\")].reset_index(drop=True)\n",
    "\n",
    "# Extract the time information and convert it to a numerical value for coloring\n",
    "germany_matches_df['Hour'] = pd.to_datetime(germany_matches_df['Time']).dt.hour\n",
    "# Extract all entries into separate lists for Germany matches\n",
    "entries = np.array(germany_matches_df['NormalizedResult'].tolist()).T\n",
    "# Define x_ticks from -9 to 6\n",
    "x_ticks = list(range(-7, 6))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot a line for each German match with a unique color\n",
    "num_matches = len(germany_matches_df)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, num_matches))\n",
    "\n",
    "for index, row in germany_matches_df.iterrows():\n",
    "    plt.plot(range(len(row['NormalizedResult'])), row['NormalizedResult'], marker='o', label=row['Match'], color=colors[index])\n",
    "\n",
    "# Set the x-ticks\n",
    "entries = np.array(germany_matches_df['NormalizedResult'].tolist())\n",
    "\n",
    "plt.xticks(ticks=range(len(entries[0])), labels=x_ticks[:len(entries[0])])\n",
    "plt.axvspan(7, 9, color='grey', alpha=0.3)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Entry Number')\n",
    "plt.ylabel('Normalized Value')\n",
    "#plt.title('Normalized Results of German Matches with Unique Colors for Each Match')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4926e9a",
   "metadata": {},
   "source": [
    "## Heatmaps stadiums per city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab3d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slots = 24\n",
    "start_date = datetime.strptime('2024-05-01', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2024-07-30', '%Y-%m-%d')\n",
    "#city='Gelsenkirchen'\n",
    "\n",
    "\n",
    "# Event details from combined_df\n",
    "event_details = combined_df[['City', 'Date', 'Time', 'Match']]\n",
    "\n",
    "# Convert Date column to datetime\n",
    "event_details['Date'] = pd.to_datetime(event_details['Date'])\n",
    "\n",
    "# Extract event times and dates\n",
    "event_times = {\n",
    "    (row['City'], datetime.strptime(row['Date'].strftime('%Y-%m-%d') + ' ' + row['Time'], '%Y-%m-%d %H:%M')): row['Match']\n",
    "    for index, row in event_details.iterrows()\n",
    "    if start_date <= row['Date'] <= end_date\n",
    "}\n",
    "\n",
    "\n",
    "# Generate the list of days\n",
    "delta = end_date - start_date\n",
    "days_list = [(start_date + timedelta(days=i)).strftime('%Y-%m-%d') for i in range(delta.days + 1)]\n",
    "print(days_list)\n",
    "\n",
    "df_total = pd.DataFrame()\n",
    "data_dict = {}\n",
    "for day in days_list:\n",
    "    query = f\"\"\"\n",
    "    WITH filtered_cnv AS (\n",
    "        SELECT cnv.*, t2p.*\n",
    "        FROM covid_network_sdkv6_tl5_10m cnv\n",
    "        JOIN tile2plz t2p ON cnv.tile_id = t2p.tile_id\n",
    "        WHERE \"day\" = '{day}'\n",
    "    ), city_filtered AS (\n",
    "        SELECT filtered_cnv.*\n",
    "        FROM filtered_cnv\n",
    "        JOIN covid_plz_populate cpp ON filtered_cnv.plz = cpp.id_plz5\n",
    "        WHERE cpp.city = '{city}'\n",
    "    )\n",
    "    SELECT cf.*, tbo.*\n",
    "    FROM city_filtered cf\n",
    "    LEFT JOIN planet_osm_polygon tbo ON ST_Intersects(cf.geopoint, tbo.way)\n",
    "    WHERE tbo.leisure = 'stadium';\n",
    "    \"\"\"\n",
    "    didlist=[]\n",
    "    pairlist=[]\n",
    "\n",
    "    df_day= pd.DataFrame(pd.read_sql_query(query, conn))\n",
    "    transformer = Transformer.from_crs(\"epsg:3857\", \"epsg:4326\")\n",
    "\n",
    "    # iterate over contact events\n",
    "    for dids, sources, in_stad, point, time in zip(df_day.dids, df_day.sources, df_day.dist_stads, df_day.geopoint, df_day.stime):\n",
    "        ngps = 1 if (in_stad==True) else 0\n",
    "        for i, si in zip(dids, sources[1:-1].split(',')):\n",
    "            for j, sj in zip(dids, sources[1:-1].split(',')):\n",
    "                if i < j and [si, sj].count('GPS') >= ngps:\n",
    "                    # collect dids in did list\n",
    "                    didlist.append(i)\n",
    "                    didlist.append(j)\n",
    "                    bytes_object = binascii.unhexlify(point)\n",
    "                    geometry = wkb.loads(bytes_object)\n",
    "                    # Transformer from EPSG:3857 to EPSG:4326\n",
    "\n",
    "                    # Assuming that `geometry` is a Point\n",
    "                    lon, lat = transformer.transform(geometry.x, geometry.y)\n",
    "                    # collect pairs of dids in pair list\n",
    "                    pairlist.append((i, j, (lon, lat, time)))\n",
    "\n",
    "    # get unique dids and did pairs\n",
    "    print(f\"Checkpoint 1 at: {datetime.now()}\")\n",
    "    didlist, pairlist = list(set(didlist)), list(set(pairlist))\n",
    "    print(len(didlist))\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(didlist)\n",
    "    print(f\"Checkpoint 2 at: {datetime.now()}\")\n",
    "\n",
    "    pairlist_multiple = consolidate_list(pairlist)\n",
    "    pairlist_multiple = [(node1, node2, sort_time(another_list)) for node1, node2, another_list in pairlist_multiple]\n",
    "    G.add_weighted_edges_from(pairlist_multiple)\n",
    "    print(len(G.edges()))\n",
    "    print(len(G.nodes()))\n",
    "    edges = list(G.edges(data=True))\n",
    "\n",
    "    for edge in edges:\n",
    "        node1, node2, attr = edge\n",
    "        for weight in attr['weight']:\n",
    "            matrix = np.zeros((1, slots), dtype=int)\n",
    "            gps_point = weight[:2]\n",
    "            timestamp = weight[2]\n",
    "            if timestamp.tzinfo is not None:\n",
    "                timestamp = timestamp.tz_localize(None)\n",
    "            hour = timestamp.hour\n",
    "            minute = timestamp.minute\n",
    "            interval_index = (hour * 60 + minute) // 60\n",
    "            matrix[0][interval_index] = 1\n",
    "            key = (node1, node2, day)\n",
    "            if key in data_dict:\n",
    "                data_dict[key]['vector'] += matrix.flatten()\n",
    "                data_dict[key]['gps_points'].append(gps_point)\n",
    "            else:\n",
    "                data_dict[key] = {\n",
    "                    'did1': node1,\n",
    "                    'did2': node2,\n",
    "                    'vector': matrix.flatten(),\n",
    "                    'gps_points': [gps_point],\n",
    "                    'day': day\n",
    "                }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e04417",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "number_of_days = len(date_range)\n",
    "organized_data = defaultdict(lambda: np.zeros((number_of_days, slots)))\n",
    "\n",
    "\n",
    "for (did1, did2, date_str), info in data_dict.items():\n",
    "    date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    index = (date - start_date).days\n",
    "    if 0 <= index < number_of_days:\n",
    "        organized_data[(did1, did2)][index, :] = info['vector']\n",
    "    else:\n",
    "        print(f\"Index {index} is out of bounds for ({did1}, {did2}) with date {date_str}\")\n",
    "\n",
    "df_rows = []\n",
    "\n",
    "for (did1, did2), vectors in organized_data.items():\n",
    "    # Create a full vector matrix initialized with zeros\n",
    "    full_vector_matrix = np.zeros((number_of_days, slots))\n",
    "\n",
    "    # Directly assign the vectors to the corresponding dates\n",
    "    full_vector_matrix[:vectors.shape[0], :vectors.shape[1]] = vectors\n",
    "    # Sum the slots per day\n",
    "    daily_sums = full_vector_matrix.sum(axis=1)\n",
    "\n",
    "\n",
    "    # Append to the DataFrame rows\n",
    "    df_rows.append({'pair': f'{did1}-{did2}', 'vector': full_vector_matrix, 'daily_sums': daily_sums})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fbbecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_rows)\n",
    "df['flattened_vector'] = df['vector'].apply(lambda x: x.reshape(-1))\n",
    "\n",
    "number_of_days = len(df['flattened_vector'].iloc[0]) // slots\n",
    "heatmap_data = np.zeros((number_of_days, slots))\n",
    "for _, row in df.iterrows():\n",
    "    matrix = np.array(row['vector']).reshape(number_of_days, slots)\n",
    "    heatmap_data += matrix\n",
    "heatmap_data_df = pd.DataFrame(heatmap_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865af254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#city='Leipzig'\n",
    "#heatmap_data_df=pd.read_csv(f'heatmap_data_stadiums_Leipzig.csv')\n",
    "#heatmap_data = heatmap_data_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bc9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap_data_df.to_csv(f'heatmap_data_stadiums_{city}.csv', index=False)\n",
    "# Flip the data for correct orientation\n",
    "heatmap_data = np.flipud(heatmap_data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df64a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Assuming heatmap_data, start_date, number_of_days, slots, city, and event_times are already defined\n",
    "\n",
    "vmax_auto = np.max(heatmap_data)\n",
    "print(vmax_auto)\n",
    "fig, ax = plt.subplots(figsize=(40, 15))\n",
    "\n",
    "# Create the heatmap without the color bar\n",
    "cax = sns.heatmap(heatmap_data, cmap='YlGnBu', vmin=0, vmax=150, ax=ax, linewidths=.5, cbar=False)\n",
    "\n",
    "# Generate all dates within the range\n",
    "dates = [start_date + timedelta(days=i) for i in range(number_of_days)]\n",
    "\n",
    "# Identify all Sundays\n",
    "sundays = [date for date in dates if date.weekday() == 6]\n",
    "\n",
    "# Select every other Sunday\n",
    "sundays_every_two_weeks = sundays[::2]\n",
    "\n",
    "# Positions of the selected Sundays in the dates list\n",
    "sunday_positions = [dates.index(sunday) for sunday in sundays_every_two_weeks]\n",
    "\n",
    "# Set x-ticks at the positions of the selected Sundays\n",
    "ax.set_xticks(sunday_positions)\n",
    "\n",
    "# Set x-tick labels as the formatted dates\n",
    "xtick_labels = [sunday.strftime('%m-%d') for sunday in sundays_every_two_weeks]\n",
    "ax.set_xticklabels(xtick_labels, ha='right', fontsize=60)\n",
    "\n",
    "# Set y-ticks every 4 hours\n",
    "ax.set_yticks([i + 3.5 for i in range(0, slots, 4)])  # Ticks at 0, 4, 8, 12, 16, 20\n",
    "\n",
    "# Set y-tick labels corresponding to every 4 hours\n",
    "ax.set_yticklabels(reversed(range(0, slots, 4)), fontsize=60, rotation=0)\n",
    "\n",
    "# Move the y-axis label slightly to the right\n",
    "ax.set_ylabel(\"hour of the day\", fontsize=70, labelpad=30)  # Adjust 'labelpad' as needed\n",
    "\n",
    "ax.set_title(f\"stadiums in {city}\", fontsize=80)\n",
    "\n",
    "# Define a threshold for deciding if the text color should be orange\n",
    "threshold=10# Adjust this value based on your data\n",
    "\n",
    "# Plot events\n",
    "for (event_city, event_time), event_name in event_times.items():\n",
    "    if event_city == city:\n",
    "        event_day_index = (event_time.date() - start_date.date()).days\n",
    "        event_hour_index = slots - 1 - event_time.hour  # Adjusted for 24 slots\n",
    "\n",
    "        match_parts = event_name.split(\" \")\n",
    "        team1 = match_parts[0][:3].upper()\n",
    "        score1 = match_parts[1]\n",
    "        score2 = match_parts[3]\n",
    "        team2 = match_parts[4][:3].upper()\n",
    "\n",
    "        team_abbreviation = f\"{team1}-{team2}\"\n",
    "        \n",
    "        # Determine if the value in heatmap_data is below the threshold\n",
    "        cell_value = heatmap_data[event_hour_index, event_day_index]\n",
    "        if cell_value < threshold:\n",
    "            text_color = 'black'\n",
    "            font_weight = 'normal'\n",
    "        else:\n",
    "            text_color = 'red'\n",
    "            font_weight = 'bold'\n",
    "        \n",
    "        ax.text(event_day_index + 0.5, event_hour_index + 0.5, team_abbreviation,\n",
    "                ha='center', va='center', color=text_color, fontsize=30, rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89721b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FF450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bbac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Define the maximum and minimum values\n",
    "max_value = 150\n",
    "min_value = 0\n",
    "\n",
    "# Use the 'YlGnBu' colormap\n",
    "cmap = plt.get_cmap('YlGnBu')\n",
    "\n",
    "# Create a gradient array for the bar\n",
    "gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "\n",
    "# Plot the horizontal bar with the gradient\n",
    "fig, ax = plt.subplots(figsize=(10, 1))  # Adjust size as needed\n",
    "\n",
    "# Display the gradient\n",
    "ax.imshow(gradient, aspect='auto', cmap=cmap, extent=[min_value, max_value, 0, 1])\n",
    "\n",
    "# Add \"Min\" and \"Max\" labels\n",
    "ax.text(min_value, 0.5, 'Min', va='center', ha='left', fontsize=20, color='black')\n",
    "ax.text(max_value, 0.5, 'Max', va='center', ha='right', fontsize=20, color='#FF4500')\n",
    "\n",
    "# Hide y-axis labels and ticks since we don't need them\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "# Hide x-axis ticks but keep the line\n",
    "ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "# Remove the frame (optional)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1aed2",
   "metadata": {},
   "source": [
    "## POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d703e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated start_date\n",
    "start_date = datetime.strptime('2024-05-01', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2024-07-30', '%Y-%m-%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cb15b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Event details from combined_df\n",
    "event_details = combined_df[['City', 'Date', 'Time', 'Match']]\n",
    "\n",
    "# Convert Date column to datetime\n",
    "event_details['Date'] = pd.to_datetime(event_details['Date'])\n",
    "\n",
    "# Extract event times and dates\n",
    "event_times = {\n",
    "    (row['City'], datetime.strptime(row['Date'].strftime('%Y-%m-%d') + ' ' + row['Time'], '%Y-%m-%d %H:%M')): row['Match']\n",
    "    for index, row in event_details.iterrows()\n",
    "    if start_date <= row['Date'] <= end_date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9392b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_match_dates = {\n",
    "    pd.to_datetime(\"2024-06-14\"): \"GER-SCO\",\n",
    "    pd.to_datetime(\"2024-06-19\"): \"GER-HUN\",\n",
    "    pd.to_datetime(\"2024-06-23\"): \"GER-SUI\",\n",
    "    pd.to_datetime(\"2024-06-29\"): \"GER-DEN\",\n",
    "    pd.to_datetime(\"2024-07-05\"): \"GER-SPA\"\n",
    "}\n",
    " \n",
    "turkey_match_dates = {\n",
    "    pd.to_datetime(\"2024-06-18\"): \"TUR-GEO\",\n",
    "    pd.to_datetime(\"2024-06-22\"): \"TUR-POR\",\n",
    "    pd.to_datetime(\"2024-06-26\"): \"TUR-CZE\",\n",
    "    pd.to_datetime(\"2024-07-02\"): \"TUR-AUS\",\n",
    "    pd.to_datetime(\"2024-07-06\"): \"TUR-NED\"\n",
    "}\n",
    " \n",
    "england_match_dates = {\n",
    "    pd.to_datetime(\"2024-06-16\"): \"ENG-SER\",\n",
    "    pd.to_datetime(\"2024-06-20\"): \"ENG-DEN\",\n",
    "    pd.to_datetime(\"2024-06-25\"): \"ENG-SLO\",\n",
    "    pd.to_datetime(\"2024-06-30\"): \"ENG-SVK\",\n",
    "    pd.to_datetime(\"2024-07-06\"): \"ENG-SUI\",\n",
    "    pd.to_datetime(\"2024-07-10\"): \"ENG-NED\",\n",
    "    pd.to_datetime(\"2024-07-14\"): \"ENG-SPA\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6859ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('heatmap_POI_germany_euro_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172003f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ff901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the heatmap data vertically to display 0 to 23 from bottom to top\n",
    "heatmap_data = df.to_numpy()\n",
    "heatmap_data= np.flipud(heatmap_data.T)\n",
    " \n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Assuming heatmap_data, start_date, number_of_days, slots, city, and event_times are already defined\n",
    "\n",
    "vmax_auto = np.max(heatmap_data)\n",
    "print(vmax_auto)\n",
    "fig, ax = plt.subplots(figsize=(40, 15))\n",
    "\n",
    "# Create the heatmap without the color bar\n",
    "cax = sns.heatmap(heatmap_data, cmap='YlGnBu', vmin=0, vmax=100\n",
    "                  , ax=ax, linewidths=.5, cbar=False)\n",
    "\n",
    "# Generate all dates within the range\n",
    "dates = [start_date + timedelta(days=i) for i in range(number_of_days)]\n",
    "\n",
    "# Identify all Sundays\n",
    "sundays = [date for date in dates if date.weekday() == 6]\n",
    "\n",
    "# Select every other Sunday\n",
    "sundays_every_two_weeks = sundays[::2]\n",
    "\n",
    "# Positions of the selected Sundays in the dates list\n",
    "sunday_positions = [dates.index(sunday) for sunday in sundays_every_two_weeks]\n",
    "\n",
    "# Set x-ticks at the positions of the selected Sundays\n",
    "ax.set_xticks(sunday_positions)\n",
    "\n",
    "# Set x-tick labels as the formatted dates\n",
    "xtick_labels = [sunday.strftime('%m-%d') for sunday in sundays_every_two_weeks]\n",
    "ax.set_xticklabels(xtick_labels, ha='right', fontsize=60)\n",
    "\n",
    "# Set y-ticks every 4 hours\n",
    "ax.set_yticks([i + 3.5 for i in range(0, slots, 4)])  # Ticks at 0, 4, 8, 12, 16, 20\n",
    "\n",
    "# Set y-tick labels corresponding to every 4 hours\n",
    "ax.set_yticklabels(reversed(range(0, slots, 4)), fontsize=60, rotation=0)\n",
    "\n",
    "# Move the y-axis label slightly to the right\n",
    "ax.set_ylabel(\"hour of the day\", fontsize=80, labelpad=30)  # Adjust 'labelpad' as needed\n",
    "\n",
    "ax.set_title('POI', fontsize=80)\n",
    "\n",
    "# Define a threshold for deciding if the text color should be orange\n",
    "threshold = 40  # Adjust this value based on your data\n",
    "\n",
    "\n",
    "# Plot events\n",
    "# Define the list of target team abbreviations\n",
    "target_teams = {\"GER\"}\n",
    "\n",
    "for (event_city, event_time), event_name in event_times.items():\n",
    "    \n",
    "    event_day_index = (event_time.date() - start_date.date()).days\n",
    "    event_hour_index = slots - 1 - event_time.hour  # Adjusted for 24 slots\n",
    "\n",
    "    match_parts = event_name.split(\" \")\n",
    "    team1 = match_parts[0][:3].upper()\n",
    "    score1 = match_parts[1]\n",
    "    score2 = match_parts[3]\n",
    "    team2 = match_parts[4][:3].upper()\n",
    "\n",
    "    team_abbreviation = f\"{team1}-{team2}\"\n",
    "\n",
    "    # Check if either team1 or team2 is in the target teams\n",
    "    if team1 in target_teams or team2 in target_teams:\n",
    "        # Determine if the value in heatmap_data is below the threshold\n",
    "        cell_value = heatmap_data[event_hour_index, event_day_index]\n",
    "        if cell_value < threshold:\n",
    "            text_color = 'black'\n",
    "            font_weight = 'normal'\n",
    "        else:\n",
    "            text_color = '#FF4500'\n",
    "            font_weight = 'bold'\n",
    "\n",
    "        ax.text(event_day_index + 0.5, event_hour_index + 0.5, team_abbreviation,\n",
    "                ha='center', va='center', color=text_color, fontsize=30, rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    " \n",
    "# Calculate projections on the x and y axes\n",
    "x_projection = np.sum(heatmap_data, axis=0)\n",
    "y_projection = np.sum(heatmap_data, axis=1)\n",
    "\n",
    "# Calculate the average contacts per day type\n",
    "day_of_week_contacts = {i: [] for i in range(7)}  # Dictionary to hold lists of contacts for each day of the week\n",
    "\n",
    "for i, date in enumerate(dates):\n",
    "    day_of_week_contacts[date.weekday()].append(x_projection[i])\n",
    "\n",
    "# Calculate the average contacts for each day of the week\n",
    "avg_day_of_week_contacts = {day: np.mean(contacts) for day, contacts in day_of_week_contacts.items()}\n",
    "\n",
    "# Normalize the x_projection by the average contacts for each day type\n",
    "normalized_x_projection = np.array([x_projection[i] / avg_day_of_week_contacts[date.weekday()] for i, date in enumerate(dates)])\n",
    "\n",
    "# Plot the normalized x-axis projection histogram\n",
    "plt.figure(figsize=(20, 15))\n",
    "colors = [\n",
    "    'purple' if date in german_match_dates else\n",
    "    'skyblue' if date in turkey_match_dates else\n",
    "    'green' if date in england_match_dates else\n",
    "    'grey'\n",
    "    for date in dates\n",
    "]  # Highlight match dates\n",
    "\n",
    "bars = plt.bar(range(len(dates)), normalized_x_projection, color=colors)  # Ensure the range matches the number of days\n",
    "\n",
    "# Generate all dates within the range\n",
    "dates = [start_date + timedelta(days=i) for i in range(number_of_days)]\n",
    "\n",
    "# Identify all Sundays\n",
    "sundays = [date for date in dates if date.weekday() == 6]\n",
    "\n",
    "# Select every other Sunday\n",
    "sundays_every_two_weeks = sundays[::2]\n",
    "\n",
    "# Positions of the selected Sundays in the dates list\n",
    "sunday_positions = [dates.index(sunday) for sunday in sundays_every_two_weeks]\n",
    "\n",
    "# Set x-ticks at the positions of the selected Sundays\n",
    "plt.xticks(sunday_positions)\n",
    "plt.yticks([])\n",
    "\n",
    "# Set x-tick labels as the formatted dates\n",
    "xtick_labels = [sunday.strftime('%m-%d') for sunday in sundays_every_two_weeks]\n",
    "plt.gca().set_xticklabels(xtick_labels, ha='right', fontsize=25)\n",
    "plt.axhline(y=1, color='red', linestyle='--', linewidth=2)\n",
    "# Add labels to the bars for match dates\n",
    "for i, bar in enumerate(bars):\n",
    "    date = dates[i]\n",
    "    match_label = None\n",
    "    if date in german_match_dates:\n",
    "        match_label = german_match_dates[date]\n",
    "    elif date in turkey_match_dates:\n",
    "        match_label = turkey_match_dates[date]\n",
    "    elif date in england_match_dates:\n",
    "        match_label = england_match_dates[date]\n",
    "    if match_label:\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height(),\n",
    "            match_label,\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            color='black',\n",
    "            fontsize=15,\n",
    "            rotation='vertical'\n",
    "        )\n",
    "\n",
    "plt.ylabel(\"number of contacts\", fontsize=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Plot the normalized x-axis projection histogram\n",
    "# Plot the normalized x-axis projection histogram\n",
    "plt.figure(figsize=(25, 15))\n",
    "colors = [\n",
    "    'purple' if date in german_match_dates else\n",
    "    'skyblue' if date in turkey_match_dates else\n",
    "    'green' if date in england_match_dates else\n",
    "    'grey'\n",
    "    for date in dates\n",
    "]  # Highlight match dates\n",
    "\n",
    "bars = plt.bar(range(len(dates)), x_projection, color=colors)\n",
    "\n",
    "# Identify all Sundays\n",
    "sundays = [date for date in dates if date.weekday() == 6]\n",
    "\n",
    "# Select every other Sunday\n",
    "sundays_every_two_weeks = sundays[::2]\n",
    "\n",
    "# Positions of the selected Sundays in the dates list\n",
    "sunday_positions = [dates.index(sunday) for sunday in sundays_every_two_weeks]\n",
    "\n",
    "# Set x-ticks at the positions of the selected Sundays\n",
    "plt.xticks(sunday_positions)\n",
    "\n",
    "# Set x-tick labels as the formatted dates for every two Sundays\n",
    "xtick_labels = [sunday.strftime('%m-%d') for sunday in sundays_every_two_weeks]\n",
    "ax = plt.gca()  # Get current axis\n",
    "ax.set_xticklabels(xtick_labels, ha='right', fontsize=30)\n",
    "\n",
    "# Add labels to the bars for match dates\n",
    "for i, bar in enumerate(bars):\n",
    "    date = dates[i]\n",
    "    match_label = None\n",
    "    if date in german_match_dates:\n",
    "        match_label = german_match_dates[date]\n",
    "    elif date in turkey_match_dates:\n",
    "        match_label = turkey_match_dates[date]\n",
    "    elif date in england_match_dates:\n",
    "        match_label = england_match_dates[date]\n",
    "    if match_label:\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height(),\n",
    "            match_label,\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            color='black',\n",
    "            fontsize=12,\n",
    "            rotation='vertical'\n",
    "        )\n",
    "\n",
    "plt.ylabel(\"number of contacts\", fontsize=60)\n",
    "plt.yticks([])\n",
    "\n",
    "#plt.title(\"Sum of Contacts Per Day\", fontsize=35)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f439139",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import norm\n",
    "from datetime import timedelta\n",
    "\n",
    "# Example match dates\n",
    "german_match_dates = {\n",
    "    pd.to_datetime(\"2024-06-14\"): \"GER-SCO\",\n",
    "    pd.to_datetime(\"2024-06-19\"): \"GER-HUN\",\n",
    "    pd.to_datetime(\"2024-06-23\"): \"GER-SUI\",\n",
    "    pd.to_datetime(\"2024-06-29\"): \"GER-DEN\",\n",
    "    pd.to_datetime(\"2024-07-05\"): \"GER-SPA\"\n",
    "}\n",
    "\n",
    "# Assuming dates, heatmap_data, and x_projection are already defined.\n",
    "\n",
    "# Group contact counts by day of the week\n",
    "day_of_week_contacts = {i: [] for i in range(7)}\n",
    "\n",
    "for i, date in enumerate(dates):\n",
    "    day = date.weekday()\n",
    "    day_of_week_contacts[day].append(x_projection[i])\n",
    "\n",
    "# Compute custom statistics for each day in the range, comparing to the distribution for the same weekday\n",
    "custom_stats = []\n",
    "p_values = []\n",
    "for i, date in enumerate(dates):\n",
    "    day = date.weekday()\n",
    "    contact_today = x_projection[i]\n",
    "    all_other_contacts = np.array([contacts for j, contacts in enumerate(day_of_week_contacts[day]) if j != i])\n",
    "\n",
    "    if len(all_other_contacts) > 1:\n",
    "        mean_contacts = np.mean(all_other_contacts)\n",
    "        std_contacts = np.std(all_other_contacts, ddof=1)\n",
    "        \n",
    "        if std_contacts > 0:\n",
    "            custom_stat = (contact_today - mean_contacts) / std_contacts\n",
    "            p_value = norm.sf(np.abs(custom_stat)) * 2  # Two-tailed test equivalent\n",
    "        else:\n",
    "            custom_stat = np.nan\n",
    "            p_value = np.nan\n",
    "        \n",
    "        custom_stats.append(custom_stat)\n",
    "        p_values.append(p_value)\n",
    "    else:\n",
    "        custom_stats.append(np.nan)\n",
    "        p_values.append(np.nan)\n",
    "\n",
    "# Plotting days vs. p-values\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Color points based on whether the day has a match in Germany\n",
    "colors = ['purple' if date in german_match_dates else 'blue' for date in dates]\n",
    "\n",
    "plt.scatter(dates, p_values, color=colors, s=100)  # s=100 for larger dots\n",
    "\n",
    "# Add a horizontal line at y=0.05 to indicate the significance threshold\n",
    "plt.axhline(y=0.05, color='green', linestyle='--', linewidth=2, label='Significance Level (0.05)')\n",
    "\n",
    "# Labeling the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('P-value', fontsize=14)\n",
    "plt.title('P-values for Daily Contact Changes Compared to the Same Day of the Week', fontsize=16)\n",
    "\n",
    "# Highlight points for matches in Germany\n",
    "for i, date in enumerate(dates):\n",
    "    if date in german_match_dates:\n",
    "        plt.text(date, p_values[i], german_match_dates[date], fontsize=12, ha='center', color='purple')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting days vs. custom statistics\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.scatter(dates, custom_stats, color=colors, s=100)  # s=100 for larger dots\n",
    "\n",
    "# Labeling the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Custom Statistic', fontsize=14)\n",
    "plt.title('Custom Statistics for Daily Contact Changes Compared to the Same Day of the Week', fontsize=16)\n",
    "\n",
    "# Highlight points for matches in Germany\n",
    "for i, date in enumerate(dates):\n",
    "    if date in german_match_dates:\n",
    "        plt.text(date, custom_stats[i], german_match_dates[date], fontsize=12, ha='center', color='purple')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5537da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
